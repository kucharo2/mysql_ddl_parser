\chapter{Debezium}
Debezium\cite{Debezium} je projekt, ktorý slúži na zaznamenávanie zmien v databáze analýzou udalostí v transakčnom logu. Jednou z podporovaných databází je taktiež MySQL. Na správnu funkcionalitu Debezium potrebuje metadáta popisujúce štruktúru databázy v závislosti na čase. Pre MySQL je to možné dosiahnuť tak, že príkazy, ktoré vytvárajú alebo upravujú štruktúru databázy (DDL) sú zachytávané, parsované a na ich základe je upravený model v pamäti, ktorý popisuje štruktúru databázy.

\section{Zachytávanie zmenených dát}
Hlavnou myšlienkou zachytávania zmenených dát, anglicky \nomExpl{CDC}{Change Data Capture}, je vytvárať sled udalostí, ktoré reprezentujú všetky zmeny v tabuľkách danej databázy. To znamená, že pre každý \textit{insert}, každý \textit{update}, každý \textit{delete} dotaz sa vytvorí jedna odpovedajúca udalosť, ktorá bude odoslaná a následne dostupná pre konzumentov tohto sledu viď obrázok \ref{fig:CDC} \cite{debezium:devoxx}. V projekte Debezium sa na sprostredkovanie sledu udalostí využíva Apache Kafka \cite{Kafka} infraštruktúra, no myšlienka CDC nie je viazaná na Kafku.

\begin{figure}[H]
\begin{center}
\includegraphics[width=15cm]{figures/CDC_1.PNG}
\caption{Koncept distribúcie zmenených dát}
\label{fig:CDC}
\end{center}
\end{figure}

\subsection{Dátové sklady}
% http://enos.itcollege.ee/~gseier/C__DOCUME~1_GUSTAV_LOCALS~1_TEMP_plugtmp_Attunity_CDC_White_Paper.pdf
V dátových skladoch sa uchovávajú dáta a ich história z viacerých databáz za účelom analytických výpočtov. Aktuálne najpoužívanejším riešením na napĺňanie dátových skladov je ETL\footnote{Export, transform, load}. Tento proces funguje v zmysle periodického nahrávania veľkého množstva dát do dátových skladov. Tento proces so sebou ale nesie nevýhody, ktoré v minulosti neboli tak podstatné, no v dnešnej dobe už sú. Použitím CDC miesto ETL je možné niektoré z týchto nevýhod obmedziť. Dátové sklady sa za pomoci CDC napĺňajú priebežne a nie periodicky, takže dáta, nad ktorými sa vykonáva analýza, budú skoro vždy aktuálne. Nakoľko sa každá zmena zapisuje jednotlivo a nie pomocou veľkého balíčka, neobmedzí to beh systémov, zamedzí nutnosti systémových prestojov a zároveň to redukuje cenu za túto operáciu. Premiestnením iba zmenených údajov CDC vyžaduje oveľa menej zdrojov na presun a transformáciu dát. To zníži náklady na hardvér, softvér a aj ľudské zdroje. \cite{attunity:etl_cdc}

\subsection{Replikácia dát}
Jedným z využití CDC je replikácia dát do iných databáz, napríklad v zmysle vytvorenia zálohy dát, ale taktiež je možné CDC využiť pri implementácií zaujímavých analytických požiadaviek. Predstavme si, že máme produkčnú databázu a špecializovaný analytický systém, na ktorom chceme spustiť analýzu. V tomto prípade je nutné dostať dáta z produkčnej databázy do analytického systému a CDC je možnosť, ktorá nám to umožní. Ďalším využitím môže byť prísun dát ostatným tímom, ktoré na základe nich môžu napríklad vypočítavať a smerovať svoju marketingovú kampaň, napríklad na užívateľov, ktorí si objednali istý konkrétny produkt. Nakoľko nechceme, aby sa takýto výpočet vykonával nad produkčnou databázou, ale skôr nad nejakou separovanou databázou, tak opäť je možné využiť CDC na propagáciu dát do separovanej databázy, kde si už marketingový tím môže vykonávať akokoľvek náročné výpočty.

\subsection{Microservice Architecture}
Ďalšie využitie CDC je vhodné pri použití Microservice architecture, kde je doména rozdelená na niekoľko služieb, ktoré potrebujú medzi sebou interagovať. Pre príklad máme tri mikro služby: objednávaciu aplikáciu na spracovávanie užívateľských objednávok, produktovú službu, ktorá sa stará o produktový katalóg, a nakoniec máme skladovú službu, ktorá kontroluje reálne množstvo produktových vecí na sklade. Je zreteľné, že na správne fungovanie bude objednávacia aplikácia vyžadovať dáta od produktovej a skladovej služby. Jednou z možností je, že objednávacia aplikácia bude priamo komunikovať s ostatnými službami, napríklad pomocou REST API\footnote{\url{https://cs.wikipedia.org/wiki/Representational_State_Transfer}}, čím ale bude úzko spojená a závislá na chode danej služby. Ak by takáto služba zlyhala/spadla, tak nebude fungovať celá aplikácia. Druhou možnosťou je práve využiť CDC, ktoré odzrkadľuje použitie Event Sourcing paternu\footnote{\url{http://microservices.io/patterns/data/event-sourcing.html}}. Produktová a skladová služba budú poskytovať sled zmenených dát a objednávacia aplikácia ich bude zachytávať a udržiavať kópiu časti týchto dát, ktoré ju zaujímajú vo vlastnej lokálnej databázy. Ak by v takomto prípade niektorá zo služieb zlyhala, tak objednávacia aplikácia môže naďalej fungovať.

\subsection{Ostatné}
Bežnou praxou vo väčších aplikáciách je používanie cache pre rýchly prístup k dátam na základe špecifických dotazov. V takýchto prípadoch je potrebné riešiť problémy updatu cache alebo jej zmazania, pokiaľ sa isté dáta zmenia.

Riešenie fulltextového vyhľadávania pomocou databázy nie je veľmi vhodné a namiesto toho sa používa SOLR\footnote{\url{http://lucene.apache.org/solr/}} alebo Elasticsearch\footnote{\url{https://www.elastic.co/}}, čo sú systémy, ktoré potrebujú byť synchronizované z dátami v primárnej databázy. 


\section{Odchytávanie zmien v databáze}
Každý databázový systém (\nom{DBMS}{Database management system}) má svoj log súbor, ktorý používa na zotavenie sa po páde a odvolaní transakcií, ktoré ešte neboli potvrdené, alebo na replikáciu dát voči sekundárnym databázam alebo inej funkcionalite. Či už to sú transakčné, binárne alebo replikačné logy, vždy v sebe udržujú všetky transakcie, ktoré boli úspešne vykonané nad databázou, a preto sú vhodné na odchytávanie zmien v databázach pre projekt Debezium. Konkrétne v MySQL databázy sa volá \textbf{binlog} (\ref{mysql:binlog}). Nakoľko sú tieto logy plne transparentné voči aplikácii, ktorá do databázy zapisuje, výkon aplikácie nebude nijako ovplyvnený čítaním týchto logov.

\subsection{Apache Kafka}
Apache Kafka je open-source distribuovateľná platforma na streamovanie správ vyvinutá firmou Apache Software Foundation. Umožňuje vytvárať a sledovať tok záznamov podobný fronte správ. Tento tok ukladá spôsobom odolným voči chybám. Hlavným použitím Kafky je vytváranie dátových potrubí v reálnom čase, ktoré spoľahlivo získavajú dáta medzi systémami alebo aplikáciami a budovanie aplikácií na streamovanie v reálnom čase, ktoré transformujú alebo reagujú na prúdy dát. Kafku je možné spustiť ako cluster na jednom alebo viacerých serveroch, ktoré ukladajú toky záznamov v kategóriách nazvaných \textbf{topiky}. Každá správa v Kafke pozostáva z kľúča, hodnoty a časovej značky. Každej správe Kafka priradí sekvenčné identifikačné číslo nazývané \textbf{offset}, ktoré unikátne identifikuje každý záznam a jeho poradie v topiku.

Kafka pozostáva zo štyroch základný API:\cite{Kafka}
\begin{itemize}
\item \textbf{Producer API}, ktoré umožňuje aplikáciám publikovať sled záznamov do jedného alebo viacerých topikov.
\item \textbf{Consumer API}, ktoré umožňuje konzumovať existujúce topiky a spracovať sled záznamov, ktorý obsahujú.
\item \textbf{Streams API}, ktoré umožňuje aplikáciám správať sa ako spracovávateľ sledu záznamov. Aplikácie pohlcujú prichádzajúci sled a produkujú transformovaný výstupný sled.
\item \textbf{Connector API}, ktorý umožňuje vytvárať znovu použiteľné dátové spojenia na publikovanie a konzumovanie záznamov, ktoré pripoja topiky k existujúcim aplikáciám alebo dátovým systémom.
\end{itemize}

\begin{figure}[H]
\begin{center}
\includegraphics[width=9cm]{figures/kafka_hierarchy.PNG}
\caption{Hierarchia Apache Kafka}
\label{fig:kafka_hierarchy}
\end{center}
\end{figure}

Projekt Debezium využíva posledné zmienené \textit{Connector API} použitím Kafka Connect frameworku (\ref{kafka_connect}), pomocou ktorého implementuje CDC pre jednotlivé databázové systémy.

\subsection{Infraštruktúra správ pomocou Apache Kafka}
Apache Kafka poskytuje sémantické pravidlá, ktoré dobre vyhovujú potrebám projektu Debezium. Prvým z nich je, že všetky správy v Kafke majú kľúč a hodnotu. Táto vlastnosť sa využíva na zjednotenie správ, ktoré spolu súvisia a to konkrétne tak, že na základe primárneho kľúča v tabuľke, ktorej sa zmena týka je možné štruktúrovať kľúč správy a hodnota správy bude reprezentovať konkrétnu zmenu.

Kafka taktiež garantuje poradie správ metódou FIFO\footnote{First in First out}, čím sa zabezpečí správne poradie zmien, ktoré bude konzument prijímať. Táto vlastnosť je veľmi dôležitá, pretože ak by nastala situácia \textit{insert} a následne \textit{update} alebo dve \textit{update} akcie za sebou, tak musí byť zabezpečené, aby sa ku konzumentovi dostali v správnom poradí, inak by mohla nastať nekonzistencia voči dátam v primárnej databázy a dátam, ktoré si udržiava konzument.

Kafka je pull-based systém, čo znamená, že konzument je sám sebe pánom a drží si informáciu o tom, ktoré správy z konkrétneho topiku už prečítal resp. kde chce začať čítanie ďalších správ. Takto môže sledovať aktuálne pribúdajúce správy, ale taktiež sa môže zaujímať aj o správy z minulosti.

Zmien v databázach môže byť veľmi veľa, čo spôsobí veľké množstvo udalostí, a preto je nutné spomenúť ďalšiu výhodu Kafky a to jej škálovateľnosť. Kafka podporuje horizontálnu škálovateľnosť a jednotlivé topiky môžu byť rozdelené na viacero partícií. Je ale nutné si uvedomiť, že poradie zmien je garantované iba na konkrétnej partícii. Kafka zabezpečí, že všetky správy s rovnakým kľúčom budú na rovnakej partícii, čím sa garantuje ich správne poradie, ale môže nastať situácia, že udalosť s iným kľúčom, ktorá reálne nastala neskôr, môže byt konzumentom spracovávaná skôr, čo môže, ale aj nemusí prekážať v závislosti na konkrétnej funkcionalite konzumenta.

\subsection{Kafka Connect}\label{kafka_connect}
Kafka Connect je framework, ktorý umožňuje jednoduchú implementáciu dátových spojení (konektorov) s Kafkou. Tieto konektory majú na starosti dáta, ktoré vstupujú alebo vystupujú z Kafky. Nazývajú sa \textit{source}(vstupujúce dáta resp. import) konektory alebo \textit{sink}(vystupujúce dáta resp. export) konektory. Debeziové konektory majú na starosti naplňovanie Kafky, takže sa používa \textit{source} konektor. Kafka Connect ponúka možnosť na riešenie offsetu. Na rozdiel od Kafka offsetu, ktorý je priradený každej správe v topiku, Kafka Connect offset si udržiava informáciu o pozícií posledného prečítaného eventu z binlogu. Môže nastať situácia, že konektor zhavaruje a bude musieť byť reštartovaný. V takomto prípade konektor potrebuje vedieť ako ďaleko v čítaní logu bol a kde má s čítaním pokračovať. 

\begin{figure}[H]
\begin{center}
\includegraphics[width=15cm]{figures/kafka_offsets.PNG}
\caption{Príklad nastavenia Kafka a Kafka Connect offsetov}
\label{fig:kafka_offsets}
\end{center}
\end{figure}

Pre príklad si povedzme, že jedna udalosť v MySQL binlogu má veľkosť 20. Na obrázku \ref{fig:kafka_offsets} je možné vidieť situáciu, kedy sa konektoru podarilo prečítať a spracovať udalosti z MySQL binlogu nachádzajúce sa na pozíciách 100 a 120. Ich príslušné správy sú dostupné v Kafke s nastaveným Kafka offsetom 1 a 2. Kafka Connect má v tejto situácií offset rovný 159, nakoľko to je posledná prečítaná pozícia. Použitím Kafka Connect je zabezpečené, že po každom spracovaní udalosti konektor potvrdí svoj offset a ak by konektor musel byť reštartovaný, tak môže zistiť posledný potvrdený offset a pokračovať v čítaní logu z nasledujúcej pozície.

Ďalším prínosom je možnosť konfigurácie schémy správ. Kafka Connect má svoj systém na definovanie typu dát, ktorým umožňuje popísať štruktúru kľúčov a hodnôt v správach. Bližšie popísané v kapitole \ref{ssec:message_structure}.

Kafka Connect je clustrovateľná, takže je možné v závislosti na špecifikácií rozdeliť konektor a jeho úlohy medzi viacero uzlov. Taktiež ponúka bohatý eko-systém konektorov. Na stránkach Confluent\footnote{\url{https://www.confluent.io/product/connectors/}} je možné stiahnuť rôzne typy či už \textit{sink} alebo \textit{source} konektorov.
Príklad CDC topológie s použitím Kafka Connect je na obrázku \ref{fig:CDC_topology} \cite{debezium:devoxx}. Zámerom v danom obrázku je zdieľať dáta dvoch tabuliek z MySQL databázy a jednej tabuľky z Postgres databázy. Každá monitorovaná tabuľka je vyjadrená jedným topikom v Kafke. Prvým krokom je nastavenie clusterov v Apache Kafka, pričom je to možné spustiť na jednom alebo viacerých clusteroch. Ďalším krokom je nastavenie Kafka Connect, ktorá je oddelená od Apache Kafka a beží v separátnych procesoch alebo clustroch a ktorá bude spravovať spojenie z Apache Kafka. Následne je nutné nasadiť inštancie Debezium konektorov do Kafka Connect a to konkrétne MySQL a Postgres konektory, nakoľko sú sledované dáta v týchto DBMS. Posledným krokom je konfigurácia aspoň jedného \textit{sink} konektoru, ktorý bude spracovávať dané topiky v Apache Kafka a odosielať ich inému systému (konzumentovi). Na konkrétnom príklade je použitý Elasticsearch konektor nakoľko je konzumentom Elasticsearch.

\begin{figure}[H]
\begin{center}
\includegraphics[width=15cm]{figures/CDC_topology.PNG}
\caption{CDC topológia z Kafka Connect}
\label{fig:CDC_topology}
\end{center}
\end{figure}

\subsection{Štruktúra správy} \label{ssec:message_structure}
Ako už bolo spomenuté, správy v Kafke obsahujú kľúč. V prípade Debezia je to primárny kľúč v tabuľke a hodnota, ktorá má komplexnejšiu štruktúru skladajúcu sa z:
\begin{itemize}
\item \textbf{before} stavu, ktorý v sebe nesie predchádzajúci stav data, ktoré sa mení. V prípade, že nastane \textit{insert} event, táto hodnota bude prázdna, nakoľko práve vzniká a nemá žiadny predchádzajúci stav.
\item \textbf{after} stavu, ktorý v sebe nesie nový stav dát. Táto hodnota môže byť opäť prázdna a to v prípade \textit{delete} udalosti.
\item \textbf{source} informácie, ktoré  obsahujú metadáta o pôvode danej zmeny. Tieto dáta sú závislé na type databázy, ktorá sa sleduje. Pre MySQL databázu sa napríklad skladá z informácií ako meno databázového serveru, názvu a pozície logovacieho súboru, z ktorého číta, názvu databázy a tabuľky, timestamp a pod.
\end{itemize}

Kafka dokáže spracovávať akýkoľvek druh textových a binárnych dát, takže jej na tejto logickej štruktúre nezáleží. Na odosielanie správ sa používajú konvertory, ktoré prevádzajú správu do formy, v ktorej bude odosielaná. Použitie Kafka Connect prináša možnosť využiť dostupné konventory, ktoré poskytuje. Pre Debezium to sú:

\begin{itemize}
\item \textbf{JSON}, do ktorého je možnosť zahrnúť informácie o schéme dát, na základe ktorej môžu konzumenti správne interpretovať prijatú správu. Tento formát je výhodné používať počas vývoja aplikácie nakoľko je čitateľný pre človeka. Ukážku správy vo formáte JSON je možné zhliadnuť v prílohe \ref{code:schemaExample}.
\item \textbf{Avro}, ktorý má veľmi efektívnu a kompaktnú reprezentáciu vhodnú na produkčné účely. Takáto správa nie je vo forme, aby ju človek bez úprav mohol prečítať, nakoľko je to binárna reprezentácia správy. V týchto správach sa nenachádza informácia o schéme tabuľky, ale iba identifikátor na danú schému a jej verziu, ktorú je možné získať pomocou registra schém, čo je ďalšia časť ekosystému Kafky. Konzument môže získať konkrétnu schému z registrov a na základe nej interpretovať binárne dáta, ktoré dostal.
\end{itemize}

% \subsection{Inicializácia}